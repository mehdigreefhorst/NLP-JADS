{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-12T13:35:15.763014Z",
     "start_time": "2024-09-12T13:35:14.971012Z"
    }
   },
   "source": "import nltk",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:35:21.059677Z",
     "start_time": "2024-09-12T13:35:17.283282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download(\"book\")\n",
    "from nltk.book import text1 as moby_dick\n",
    "print(moby_dick.tokens[:20])"
   ],
   "id": "55c282eae64c052c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'book'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection book\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n",
      "['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']', 'ETYMOLOGY', '.', '(', 'Supplied', 'by', 'a', 'Late', 'Consumptive', 'Usher', 'to', 'a', 'Grammar']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:35:44.123038Z",
     "start_time": "2024-09-12T13:35:44.120813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_lexical_variation(unique_words, total_words):\n",
    "    return len(unique_words)/len(total_words)"
   ],
   "id": "e3f86ef5cf2f4cb3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:35:44.549862Z",
     "start_time": "2024-09-12T13:35:44.539450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the total number of tokens of the book\n",
    "tokens_moby_dick = moby_dick.tokens\n",
    "unique_tokens_moby_dick = set(tokens_moby_dick)\n",
    "\n",
    "print(f\"total tokens moby dick = {len(tokens_moby_dick)} \\n unique tokens moby dick = {len(unique_tokens_moby_dick)}\")\n",
    "print(f\"lexical variation = {calculate_lexical_variation(unique_tokens_moby_dick, tokens_moby_dick)}\")"
   ],
   "id": "e359bbef4d647f0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens moby dick = 260819 \n",
      " unique tokens moby dick = 19317\n",
      "lexical variation = 0.07406285585022564\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:36:15.059965Z",
     "start_time": "2024-09-12T13:36:15.056393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove all the stopwords from the document.\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ],
   "id": "b1d438d7524f5d04",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mehdigreefhorst/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:36:15.437143Z",
     "start_time": "2024-09-12T13:36:15.431943Z"
    }
   },
   "cell_type": "code",
   "source": "stopwords_all = stopwords.words()",
   "id": "b5376ff195a0d5c3",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:36:45.403180Z",
     "start_time": "2024-09-12T13:36:28.498264Z"
    }
   },
   "cell_type": "code",
   "source": "tokens_without_stopwords = [token for token in tokens_moby_dick if token not in stopwords_all]",
   "id": "1303a93adc6bb7a5",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:47:52.519746Z",
     "start_time": "2024-09-12T13:47:52.497192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import string\n",
    "punctuation_char = string.punctuation\n",
    "tokens_without_punctuation = [token.strip(punctuation_char) for token in tokens_without_stopwords]\n",
    "\n",
    "for word in tokens_without_punctuation:\n",
    "    if not word.isalpha() and len(word)>0:\n",
    "        print(word)\n",
    "        print(\"There is punctuation left!!!\")"
   ],
   "id": "4862fd32627459b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851\n",
      "There is punctuation left!!!\n",
      "890\n",
      "There is punctuation left!!!\n",
      "1671\n",
      "There is punctuation left!!!\n",
      "1652\n",
      "There is punctuation left!!!\n",
      "500\n",
      "There is punctuation left!!!\n",
      "1668\n",
      "There is punctuation left!!!\n",
      "1729\n",
      "There is punctuation left!!!\n",
      "1772\n",
      "There is punctuation left!!!\n",
      "1778\n",
      "There is punctuation left!!!\n",
      "40\n",
      "There is punctuation left!!!\n",
      "1690\n",
      "There is punctuation left!!!\n",
      "1821\n",
      "There is punctuation left!!!\n",
      "10\n",
      "There is punctuation left!!!\n",
      "440\n",
      "There is punctuation left!!!\n",
      "1839\n",
      "There is punctuation left!!!\n",
      "1840\n",
      "There is punctuation left!!!\n",
      "13\n",
      "There is punctuation left!!!\n",
      "1846\n",
      "There is punctuation left!!!\n",
      "1828\n",
      "There is punctuation left!!!\n",
      "1828\n",
      "There is punctuation left!!!\n",
      "1\n",
      "There is punctuation left!!!\n",
      "2\n",
      "There is punctuation left!!!\n",
      "3\n",
      "There is punctuation left!!!\n",
      "4\n",
      "There is punctuation left!!!\n",
      "21st\n",
      "There is punctuation left!!!\n",
      "5\n",
      "There is punctuation left!!!\n",
      "6\n",
      "There is punctuation left!!!\n",
      "7\n",
      "There is punctuation left!!!\n",
      "1st\n",
      "There is punctuation left!!!\n",
      "1836\n",
      "There is punctuation left!!!\n",
      "31st\n",
      "There is punctuation left!!!\n",
      "1839\n",
      "There is punctuation left!!!\n",
      "3d\n",
      "There is punctuation left!!!\n",
      "1833\n",
      "There is punctuation left!!!\n",
      "8\n",
      "There is punctuation left!!!\n",
      "9\n",
      "There is punctuation left!!!\n",
      "10\n",
      "There is punctuation left!!!\n",
      "11\n",
      "There is punctuation left!!!\n",
      "12\n",
      "There is punctuation left!!!\n",
      "13\n",
      "There is punctuation left!!!\n",
      "14\n",
      "There is punctuation left!!!\n",
      "15\n",
      "There is punctuation left!!!\n",
      "16\n",
      "There is punctuation left!!!\n",
      "275th\n",
      "There is punctuation left!!!\n",
      "275th\n",
      "There is punctuation left!!!\n",
      "275th\n",
      "There is punctuation left!!!\n",
      "275th\n",
      "There is punctuation left!!!\n",
      "200th\n",
      "There is punctuation left!!!\n",
      "17\n",
      "There is punctuation left!!!\n",
      "18\n",
      "There is punctuation left!!!\n",
      "19\n",
      "There is punctuation left!!!\n",
      "20\n",
      "There is punctuation left!!!\n",
      "21\n",
      "There is punctuation left!!!\n",
      "22\n",
      "There is punctuation left!!!\n",
      "23\n",
      "There is punctuation left!!!\n",
      "24\n",
      "There is punctuation left!!!\n",
      "1750\n",
      "There is punctuation left!!!\n",
      "1788\n",
      "There is punctuation left!!!\n",
      "L1\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "4\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "20\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "7\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "25\n",
      "There is punctuation left!!!\n",
      "26\n",
      "There is punctuation left!!!\n",
      "27\n",
      "There is punctuation left!!!\n",
      "28\n",
      "There is punctuation left!!!\n",
      "29\n",
      "There is punctuation left!!!\n",
      "30\n",
      "There is punctuation left!!!\n",
      "31\n",
      "There is punctuation left!!!\n",
      "32\n",
      "There is punctuation left!!!\n",
      "1820\n",
      "There is punctuation left!!!\n",
      "1839\n",
      "There is punctuation left!!!\n",
      "1776\n",
      "There is punctuation left!!!\n",
      "1850\n",
      "There is punctuation left!!!\n",
      "1\n",
      "There is punctuation left!!!\n",
      "33\n",
      "There is punctuation left!!!\n",
      "34\n",
      "There is punctuation left!!!\n",
      "35\n",
      "There is punctuation left!!!\n",
      "36\n",
      "There is punctuation left!!!\n",
      "37\n",
      "There is punctuation left!!!\n",
      "38\n",
      "There is punctuation left!!!\n",
      "39\n",
      "There is punctuation left!!!\n",
      "40\n",
      "There is punctuation left!!!\n",
      "1ST\n",
      "There is punctuation left!!!\n",
      "2ND\n",
      "There is punctuation left!!!\n",
      "3D\n",
      "There is punctuation left!!!\n",
      "4TH\n",
      "There is punctuation left!!!\n",
      "5TH\n",
      "There is punctuation left!!!\n",
      "41\n",
      "There is punctuation left!!!\n",
      "42\n",
      "There is punctuation left!!!\n",
      "43\n",
      "There is punctuation left!!!\n",
      "44\n",
      "There is punctuation left!!!\n",
      "16th\n",
      "There is punctuation left!!!\n",
      "1851\n",
      "There is punctuation left!!!\n",
      "45\n",
      "There is punctuation left!!!\n",
      "1820\n",
      "There is punctuation left!!!\n",
      "45\n",
      "There is punctuation left!!!\n",
      "1807\n",
      "There is punctuation left!!!\n",
      "46\n",
      "There is punctuation left!!!\n",
      "47\n",
      "There is punctuation left!!!\n",
      "48\n",
      "There is punctuation left!!!\n",
      "49\n",
      "There is punctuation left!!!\n",
      "50\n",
      "There is punctuation left!!!\n",
      "51\n",
      "There is punctuation left!!!\n",
      "52\n",
      "There is punctuation left!!!\n",
      "53\n",
      "There is punctuation left!!!\n",
      "54\n",
      "There is punctuation left!!!\n",
      "55\n",
      "There is punctuation left!!!\n",
      "15th\n",
      "There is punctuation left!!!\n",
      "1671\n",
      "There is punctuation left!!!\n",
      "1793\n",
      "There is punctuation left!!!\n",
      "1807\n",
      "There is punctuation left!!!\n",
      "1825\n",
      "There is punctuation left!!!\n",
      "1836\n",
      "There is punctuation left!!!\n",
      "56\n",
      "There is punctuation left!!!\n",
      "57\n",
      "There is punctuation left!!!\n",
      "58\n",
      "There is punctuation left!!!\n",
      "59\n",
      "There is punctuation left!!!\n",
      "60\n",
      "There is punctuation left!!!\n",
      "61\n",
      "There is punctuation left!!!\n",
      "62\n",
      "There is punctuation left!!!\n",
      "63\n",
      "There is punctuation left!!!\n",
      "64\n",
      "There is punctuation left!!!\n",
      "65\n",
      "There is punctuation left!!!\n",
      "66\n",
      "There is punctuation left!!!\n",
      "67\n",
      "There is punctuation left!!!\n",
      "68\n",
      "There is punctuation left!!!\n",
      "69\n",
      "There is punctuation left!!!\n",
      "70\n",
      "There is punctuation left!!!\n",
      "71\n",
      "There is punctuation left!!!\n",
      "72\n",
      "There is punctuation left!!!\n",
      "73\n",
      "There is punctuation left!!!\n",
      "74\n",
      "There is punctuation left!!!\n",
      "75\n",
      "There is punctuation left!!!\n",
      "500\n",
      "There is punctuation left!!!\n",
      "76\n",
      "There is punctuation left!!!\n",
      "77\n",
      "There is punctuation left!!!\n",
      "78\n",
      "There is punctuation left!!!\n",
      "79\n",
      "There is punctuation left!!!\n",
      "80\n",
      "There is punctuation left!!!\n",
      "81\n",
      "There is punctuation left!!!\n",
      "2000\n",
      "There is punctuation left!!!\n",
      "82\n",
      "There is punctuation left!!!\n",
      "83\n",
      "There is punctuation left!!!\n",
      "84\n",
      "There is punctuation left!!!\n",
      "85\n",
      "There is punctuation left!!!\n",
      "1851\n",
      "There is punctuation left!!!\n",
      "86\n",
      "There is punctuation left!!!\n",
      "87\n",
      "There is punctuation left!!!\n",
      "88\n",
      "There is punctuation left!!!\n",
      "89\n",
      "There is punctuation left!!!\n",
      "1695\n",
      "There is punctuation left!!!\n",
      "L100\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "L100\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "1492\n",
      "There is punctuation left!!!\n",
      "90\n",
      "There is punctuation left!!!\n",
      "3\n",
      "There is punctuation left!!!\n",
      "3\n",
      "There is punctuation left!!!\n",
      "L150\n",
      "There is punctuation left!!!\n",
      "91\n",
      "There is punctuation left!!!\n",
      "92\n",
      "There is punctuation left!!!\n",
      "1791\n",
      "There is punctuation left!!!\n",
      "93\n",
      "There is punctuation left!!!\n",
      "94\n",
      "There is punctuation left!!!\n",
      "95\n",
      "There is punctuation left!!!\n",
      "15th\n",
      "There is punctuation left!!!\n",
      "96\n",
      "There is punctuation left!!!\n",
      "97\n",
      "There is punctuation left!!!\n",
      "98\n",
      "There is punctuation left!!!\n",
      "99\n",
      "There is punctuation left!!!\n",
      "100\n",
      "There is punctuation left!!!\n",
      "101\n",
      "There is punctuation left!!!\n",
      "1775\n",
      "There is punctuation left!!!\n",
      "1775\n",
      "There is punctuation left!!!\n",
      "1726\n",
      "There is punctuation left!!!\n",
      "1778\n",
      "There is punctuation left!!!\n",
      "1819\n",
      "There is punctuation left!!!\n",
      "180\n",
      "There is punctuation left!!!\n",
      "400\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "60\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "150\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "550\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "72\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "2\n",
      "There is punctuation left!!!\n",
      "800\n",
      "There is punctuation left!!!\n",
      "20\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "144\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "550\n",
      "There is punctuation left!!!\n",
      "10\n",
      "There is punctuation left!!!\n",
      "800\n",
      "There is punctuation left!!!\n",
      "10\n",
      "There is punctuation left!!!\n",
      "800\n",
      "There is punctuation left!!!\n",
      "30\n",
      "There is punctuation left!!!\n",
      "180\n",
      "There is punctuation left!!!\n",
      "5\n",
      "There is punctuation left!!!\n",
      "400\n",
      "There is punctuation left!!!\n",
      "550\n",
      "There is punctuation left!!!\n",
      "102\n",
      "There is punctuation left!!!\n",
      "103\n",
      "There is punctuation left!!!\n",
      "104\n",
      "There is punctuation left!!!\n",
      "1779\n",
      "There is punctuation left!!!\n",
      "1842\n",
      "There is punctuation left!!!\n",
      "25\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "105\n",
      "There is punctuation left!!!\n",
      "3\n",
      "There is punctuation left!!!\n",
      "1825\n",
      "There is punctuation left!!!\n",
      "13\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "4\n",
      "There is punctuation left!!!\n",
      "000\n",
      "There is punctuation left!!!\n",
      "106\n",
      "There is punctuation left!!!\n",
      "107\n",
      "There is punctuation left!!!\n",
      "108\n",
      "There is punctuation left!!!\n",
      "109\n",
      "There is punctuation left!!!\n",
      "110\n",
      "There is punctuation left!!!\n",
      "111\n",
      "There is punctuation left!!!\n",
      "112\n",
      "There is punctuation left!!!\n",
      "113\n",
      "There is punctuation left!!!\n",
      "114\n",
      "There is punctuation left!!!\n",
      "115\n",
      "There is punctuation left!!!\n",
      "116\n",
      "There is punctuation left!!!\n",
      "117\n",
      "There is punctuation left!!!\n",
      "118\n",
      "There is punctuation left!!!\n",
      "119\n",
      "There is punctuation left!!!\n",
      "120\n",
      "There is punctuation left!!!\n",
      "121\n",
      "There is punctuation left!!!\n",
      "122\n",
      "There is punctuation left!!!\n",
      "123\n",
      "There is punctuation left!!!\n",
      "124\n",
      "There is punctuation left!!!\n",
      "125\n",
      "There is punctuation left!!!\n",
      "126\n",
      "There is punctuation left!!!\n",
      "127\n",
      "There is punctuation left!!!\n",
      "128\n",
      "There is punctuation left!!!\n",
      "129\n",
      "There is punctuation left!!!\n",
      "130\n",
      "There is punctuation left!!!\n",
      "131\n",
      "There is punctuation left!!!\n",
      "132\n",
      "There is punctuation left!!!\n",
      "133\n",
      "There is punctuation left!!!\n",
      "134\n",
      "There is punctuation left!!!\n",
      "135\n",
      "There is punctuation left!!!\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:53:13.010315Z",
     "start_time": "2024-09-12T13:53:13.008Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3f00a7ace9d21f9c",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:53:13.374892Z",
     "start_time": "2024-09-12T13:53:13.362076Z"
    }
   },
   "cell_type": "code",
   "source": "from collections import Counter",
   "id": "a29741a95b231480",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Counter\n\u001B[0;32m----> 2\u001B[0m \u001B[43mCounter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmost_common\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens_without_punctuation\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.4/lib/python3.12/collections/__init__.py:628\u001B[0m, in \u001B[0;36mCounter.most_common\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;66;03m# Emulate Bag.sortedByCount from Smalltalk\u001B[39;00m\n\u001B[1;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 628\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m(), key\u001B[38;5;241m=\u001B[39m_itemgetter(\u001B[38;5;241m1\u001B[39m), reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    630\u001B[0m \u001B[38;5;66;03m# Lazy import to speedup Python startup time\u001B[39;00m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mheapq\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:57:49.926562Z",
     "start_time": "2024-09-12T13:57:49.909494Z"
    }
   },
   "cell_type": "code",
   "source": "Counter(tokens_without_punctuation).most_common()[-10:]",
   "id": "6ef25bf474478f5a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('closing', 1),\n",
       " ('Ixion', 1),\n",
       " ('Till', 1),\n",
       " ('liberated', 1),\n",
       " ('Buoyed', 1),\n",
       " ('dirgelike', 1),\n",
       " ('padlocks', 1),\n",
       " ('sheathed', 1),\n",
       " ('retracing', 1),\n",
       " ('orphan', 1)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d4cf0ddfb41ee7d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T13:58:20.239808Z",
     "start_time": "2024-09-12T13:58:20.210253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_least_common_words(list_of_words):\n",
    "    counter = Counter(list_of_words).most_common()\n",
    "    \n",
    "    return counter[-10:]\n",
    "\n",
    "def get_most_common_words(list_of_words):\n",
    "    counter = Counter(list_of_words).most_common(10)\n",
    "    return counter\n",
    "\n",
    "least_common_words = get_least_common_words(tokens_without_punctuation)\n",
    "most_common_words = get_most_common_words(tokens_without_punctuation)\n",
    "\n",
    "print(f\"least common words = {least_common_words} \\n most common words = {most_common_words}\")"
   ],
   "id": "cb1c98c4c05aecc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least common words = [('closing', 1), ('Ixion', 1), ('Till', 1), ('liberated', 1), ('Buoyed', 1), ('dirgelike', 1), ('padlocks', 1), ('sheathed', 1), ('retracing', 1), ('orphan', 1)] \n",
      " most common words = [('', 42200), ('I', 2124), ('whale', 906), ('But', 705), ('The', 612), ('ship', 507), ('Ahab', 501), ('And', 369), ('head', 335), ('boat', 330)]\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a7da79687dc4d9c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
